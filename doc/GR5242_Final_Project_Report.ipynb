{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GR5242 Final Project Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team members:\n",
    "- Jia, Kewei (kj2408@columbia.edu)\n",
    "- Zhang, Yini (yz3005@columbia.edu)\n",
    "- Zhu, Chenyun (cz2434@columbia.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html) is an important image classification dataset. It consists of 60000 32x32 colour images in 10 classes (airplanes, automobiles, birds, cats, deer, dogs, frogs, horses, ships, and trucks), with 6000 images per class. There are 50000 training images and 10000 test images.<br>\n",
    "\n",
    "The **GOALS** of this project are to:\n",
    "- Learn how to preprocess the image data\n",
    "- Implement different Convolutional Neural Networks (CNN) classifiers using GPU-enabled Tensorflow and Keras API\n",
    "- Compare different CNN architectures\n",
    "\n",
    "**Tools:**\n",
    "- GPU-enabled Tensorflow\n",
    "- Keras API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Exploration & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Please refer to the *Data Exploration and Preprocessing.ipynb* for detailed code.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The version we used is [CIFAR-10 python version](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz).\n",
    "\n",
    "The original CIFAR 10 training dataset has five batches of files, each contains 10,000 images. The test dataset has one file that contains 10,000 images. We use functions in our script **load_data_helper_functions.py** to load both images and labels in training and test data.\n",
    "\n",
    "The training set we get is numpy ndarray with shape (50,000, 3072) and test set is numpy ndarray with shape (10,000, 3072). Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n",
    "\n",
    "The labels for training and test dataset are numpy array with shape (50,000, 1) and (10,000, 1). They are not one-hot-encoding yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we reshape each row into a (32,32,3) numpy array, with one inner array as one pixel with three channels: red, green and blue. The reshaped training data is of shape (50,000, 32, 32, 3). The reshaped test data is of shape (10,000, 32, 32, 3).\n",
    "\n",
    "Then we plot the first 10 images in training set with true class labels. This is for better understanding of the dataset. The images are plotted using functions in our script **preprocess_data.py**.\n",
    "\n",
    "__The first 10 images in training set:__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"http://drive.google.com/uc?export=view&id=1KfGNI0WfoZbZwjokrwyKwh9OdqNvRAlu\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare data for training CNN models, we do the following things: \n",
    "\n",
    "First, we convert image labels to one-hot-encoding.\n",
    "\n",
    "Next, we inflate the size of training dataset by adding randomly distorted images which are cropped, horizontally flipped, or adjusted in terms of hue, contrast and saturation. This way of distorting images will include different variation of images in training set, and will therefore make the CNN model we trained to generalize better in test dataset. We got this idea of data preprocessing from [Magnus Erik Hvass Pedersen](http://www.hvass-labs.org/).\n",
    "\n",
    "Last, the test dataset will be images cropped around center without any other adjustment. The cropped size is the same as that in training set.\n",
    "\n",
    "__Plot the distorted image__<br>\n",
    "Here are 10 examples of the 321st image in test dataset after preprocessing:\n",
    "\n",
    "<img style=\"float: left;\" src=\"http://drive.google.com/uc?export=view&id=1vW_iW7FQQpbenLvFT1-Cx4mtgIi_1kEV\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the distorted images are eithered flipped or adjusted in some way that varies from original image. These images will later be used to train CNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convolutional Neural Networks (CNN) From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with, we build a CNN classifier from scratch and explore details to understand how convolution works. <br>\n",
    "\n",
    "(Please refer to the *CNN_Scratch.ipynb* for detailed code.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We trained the model with 1000 epochs.<br>\n",
    "In each epoch, we have 500 batches, each with batch size of 100. <br>\n",
    "The learning rate is 0.05. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Architecture:__ <br>\n",
    "input = ($32\\times32\\times3$) -- <br>\n",
    "Image Preprocessing: cropped images to shape ($24\\times24\\times3$) -- <br>\n",
    "\n",
    "2D convolution layer with filters size $64$ and kernel size $5\\times5$ plus ReLU activation -- <br>\n",
    "2D Maxpooling -- <br>\n",
    "\n",
    "2D convolution layer with filters size $64$ and kernel size $5\\times5$ plus ReLU activation -- <br>\n",
    "2D Maxpooling -- <br>\n",
    "20% Dropout -- <br>\n",
    "\n",
    "Softmax Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I. Train/Test Accurarcy and Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left; width:60%\" src=\"http://drive.google.com/uc?export=view&id=1ghfpYuJu6xT2qU4mL8WPA2aJFp68dU95\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Insights **:<br>\n",
    "We used GPU to train, and the training for 1000 epochs takes around 10 hours. <br>\n",
    "After 1000 epochs, the accuracy on test dataset is around 64%, and the accuray on training set is a slightly higher 65%. <br>\n",
    "Overfitting exists but not a serious problem. In both accuracy and model plot, test and train lines stay close to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems from the plot that the model still needs more time to train since accuracy displays the trend of increasing and is not stablized yet. However, due to computation restraint, we did not proceed further. We believe that if continuing to train this CNN model with more epochs, the final accurarcy will keep improving. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II. Examples of Mis-classified Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are 10 examples of images that are predicted wrong by CNN classifiers. \n",
    "\n",
    "Some of the images are really hard even for humans to detect the difference. The third one in first row resembles a lot as the shape of cat, and the fifth one in row is similar to the color of frog. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left; width:60%\" src=\"http://drive.google.com/uc?export=view&id=1FCmsI5xr8PLuE_XyUBq4cFtMWN8q4cOU\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### III. Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use confusion matrix to see which of the classes are more likely to be misclassified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left; width:60%\" src=\"http://drive.google.com/uc?export=view&id=1C6o64PxIbve57B1pkRUbxNSWa5H_rpKZ\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above demonstrated the confusion matrix for one batch (100 images total) of test dataset. <br>\n",
    "Automobiles are less likely to be misclassified, whereas 50% of airplanes are given the wrong labels. Although airplanes are usually classified wrongly, they are often mistaken as objects instead of animals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convolutional Neural Networks (CNN) with Keras\n",
    "### 3-1. Brief Introduction for Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\"Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano.1.\"*[1] The reasons we tried Keras are as follows:\n",
    "- Easy to get started with\n",
    "- Results in much more readable and succinct code\n",
    "- Able to run on GPU (much faster than CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. CNN with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__I. We first created the basic CNN with 100 Epochs.__<br>\n",
    "(Please refer to the *Keras_CNN_Baseline.ipynb* for detailed code.)\n",
    "\n",
    "__Architecture:__ <br>\n",
    "input = ($32\\times32\\times3$) -- <br>\n",
    "2D convolution layer with filters size $32$ and kernel size $3\\times3$ plus ReLU activation -- <br>\n",
    "2D convolution layer with filters size $32$ and kernel size $3\\times3$ plus ReLU activation -- <br>\n",
    "2D Maxpooling -- <br>\n",
    "20% Dropout -- <br>\n",
    "\n",
    "2D convolution layer with filters size $64$ and kernel size $3\\times3$ plus ReLU activation -- <br>\n",
    "2D convolution layer with filters size $64$ and kernel size $3\\times3$ plus ReLU activation -- <br>\n",
    "2D Maxpooling -- <br>\n",
    "25% Dropout -- <br>\n",
    "\n",
    "Softmax Output\n",
    "\n",
    "__Baseline CNN Result:__\n",
    "\n",
    "<img style=\"float: left; width:60%\" src=\"http://drive.google.com/uc?export=view&id=1tvqt-_HYvtX_ystbJI6_BShUBYFmmLju\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Insights:__ <br>\n",
    "Notice that the test result is 79.7%. Let's try to add more layers to the model and see if the test accuracy has any improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__II. Now we added more layers to the previous model.__<br>\n",
    "(Please refer to the *Keras_CNN_Baseline_More_Layer.ipynb* for detailed code.)\n",
    "\n",
    "__Architecture:__ <br>\n",
    "input = ($32\\times32\\times3$) -- <br>\n",
    "2D convolution layer with filters size $32$ and kernel size $3\\times3$ plus ReLU activation -- <br>\n",
    "2D convolution layer with filters size $32$ and kernel size $3\\times3$ plus ReLU activation -- <br>\n",
    "2D Maxpooling -- <br>\n",
    "20% Dropout -- <br>\n",
    "\n",
    "2D convolution layer with filters size $64$ and kernel size $3\\times3$ plus ReLU activation -- <br>\n",
    "2D convolution layer with filters size $64$ and kernel size $3\\times3$ plus ReLU activation -- <br>\n",
    "2D Maxpooling -- <br>\n",
    "25% Dropout -- <br>\n",
    "\n",
    "2D convolution layer with filters size $128$ and kernel size $3\\times3$ plus ReLU activation -- <br>\n",
    "2D convolution layer with filters size $128$ and kernel size $3\\times3$ plus ReLU activation -- <br>\n",
    "2D Maxpooling -- <br>\n",
    "30% Dropout -- <br>\n",
    "\n",
    "Softmax Output\n",
    "\n",
    "__Baseline CNN with More Layers Result:__\n",
    "\n",
    "<img style=\"float: left; width:60%\" src=\"http://drive.google.com/uc?export=view&id=1G6JkT3F9v9bsPhcOXLqdVvrbZ0YQUs2u\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Insights:__<br>\n",
    "The good thing is test accuracy increases from 79.7% to 83.1%. However, the model seems overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__III. Try to prevent overfitting by adding batchnormalization and kernel regularizer__<br>\n",
    "Idea from the Kaggle comment of [EricAlcaideAldeano](https://www.kaggle.com/ericalcaide9834/discussion). <br>\n",
    "(Please refer to the *Keras_CNN_Prevent_Overfitting.ipynb* for detailed code.)\n",
    "\n",
    "__Architecture:__ <br>\n",
    "input = ($32\\times32\\times3$) -- <br>\n",
    "2D convolution layer with filters size $32$ and kernel size $3\\times3$ plus ReLU activation and *regularizer(0.001)* -- <br>\n",
    "*BatchNormalization* -- <br>\n",
    "2D convolution layer with filters size $32$ and kernel size $3\\times3$ plus ReLU activation and *regularizer(0.001)* -- <br>\n",
    "*BatchNormalization* -- <br>\n",
    "2D Maxpooling -- <br>\n",
    "20% Dropout -- <br>\n",
    "\n",
    "2D convolution layer with filters size $64$ and kernel size $3\\times3$ plus ReLU activation and *regularizer(0.001)* -- <br>\n",
    "*BatchNormalization* -- <br>\n",
    "2D convolution layer with filters size $64$ and kernel size $3\\times3$ plus ReLU activation and *regularizer(0.001)* -- <br>\n",
    "*BatchNormalization* -- <br>\n",
    "2D Maxpooling -- <br>\n",
    "25% Dropout -- <br>\n",
    "\n",
    "2D convolution layer with filters size $128$ and kernel size $3\\times3$ plus ReLU activation and *regularizer(0.001)* -- <br>\n",
    "*BatchNormalization* -- <br>\n",
    "2D convolution layer with filters size $128$ and kernel size $3\\times3$ plus ReLU activation and *regularizer(0.001)* -- <br>\n",
    "*BatchNormalization* -- <br>\n",
    "2D Maxpooling -- <br>\n",
    "30% Dropout -- <br>\n",
    "Softmax Output\n",
    "\n",
    "__ Previous Model with Batchnorm and Kernel Regularizer Added Result:__\n",
    "\n",
    "<img style=\"float: left; width:60%\" src=\"http://drive.google.com/uc?export=view&id=1zGp093ocKkfTrV5vEImBr76FeTLwdkHm\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Insights:__<br>\n",
    "After applied batchnormalization and regularizer, we can see the test accuracy 85.2% is better than the previous model 83.1%. In addition, the generalization of the model improves as we can see in the graph (the gap between training accuracy and validation accuracy is smaller than before)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Findings of CNN with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add relatively more layers can achieve higher accuracy\n",
    "- Batchnormalization and kernel regularizaer can help us prevent overfitting and keep the weights small so that the model can generalize well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply data augmentation to the model. It takes 17 hours to run 25 epochs so the limited time is the main challenge for us to add data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Discussions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1. Summarize the Findings\n",
    "- Data preprocessing is important if we try to build a good classifier\n",
    "- Add relatively more layers can achieve higher accuracy\n",
    "- Batchnormalization and kernel regularizaer can help us prevent overfitting\n",
    "\n",
    "### 4-2. Model Comparison\n",
    "\n",
    "When comparing CNN classifiers built from scratch with the ones built with Keras, it is not difficult to find that Keras perform better with a much faster speed. It is interesting to see that in the early phases, even in the very first epoch, Keras models start with a quite high test accurarcy of around 0.6. Scratch models, however, learn from the very beginning, and uses almost 500 epochs to increase accurarcy from 0.2 to 0.6. One thing that may causes this is the choice of initializer[2]. It might be that Keras have already embedded some better inits by learning from empiricism to skip the time consuming early training phases.\n",
    "\n",
    "Another difference is about overfitting. Both scratch model and Keras models use drop-out layers. However, Keras models tend to overfit compared with scratch model. This is probably because, in each epoch of scratch model, we run through all images in train set with a batch size of 100 before going to next epoch, which means that in each epoch, scratch CNN takes 500 steps. This makes the scratch CNN to learn slower but more carefully than Keras. It can also be seen from the very dense curves in scratch CNN and relatively sparse curves in Keras results plots.\n",
    "\n",
    "### 4-3. Our other trials\n",
    "\n",
    "At the beginning of our project, we also tried other different architectures:\n",
    "- Logistic regression with accuracy ~ 28% (Please refer to the *logistic_reg.py* for detailed code.)\n",
    "- Conv -- fc with accuracy ~ 40% (Please refer to the *conv_fc.py* for detailed code.)\n",
    "- Conv -- conv -- fc -- fc with accuracy ~ 50% (Please refer to the *cnn_deep.py* for detailed code.)\n",
    "- Fractional max pooling [3] with accuracy ~ 58% (Please refer to the *fractional_max_pool.py* for detailed code.)\n",
    "\n",
    "### 4-4. Future Improvements\n",
    "- Add data augmentation\n",
    "- Try decrease the learning rate as epoch increases\n",
    "- Train the model with more time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) *Keras: The Python Deep Learning Library. keras.io/#keras-the-python-deep-learning-library.* <br>\n",
    "(2) *Mishkin, D., & Matas, J. (2015). All you need is a good init. arXiv preprint arXiv:1511.06422. Chicago*\t<br>\n",
    "(3) *Graham, B. (2014). Fractional max-pooling. arXiv preprint arXiv:1412.6071.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
