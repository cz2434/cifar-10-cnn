{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Exploration and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The detailed code of this part is in *Data Exploration and Preprocessing.ipynb*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1 Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) is consisted of 32x32 colour images in 10 classes, with 6,000 images per class. The version we used is [CIFAR-10 python version](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz). The total number of images in training and test set are 50,000 and 10,000 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original CIFAR 10 training dataset has five batches of files, each contains 10,000 images. The test dataset has one file that contains 10,000 images. We use functions in our script **load_data_helper_functions.py** to load both images and labels in training and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set we get is numpy ndarray with shape (50,000, 3072) and test set is numpy ndarray with shape (10,000, 3072). Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n",
    "\n",
    "The labels for training and test dataset are numpy array with shape (50,000, 1) and (10,000, 1). They are not one-hot-encoding yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2 Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we reshape each row into a (32,32,3) numpy array, with one inner array as one pixel with three channels: red, green and blue. The reshaped training data is of shape (50,000, 32, 32, 3). The reshaped test data is of shape (10,000, 32, 32, 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we plot the first 10 images in training set with true class labels. This is for better understanding of the dataset. The images are plotted using functions in our script **preprocess_data.py**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first 10 images in training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"../figs/first10.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3 Data Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare data for training CNN models, we do the following things: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we convert image labels to one-hot-encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we inflate the size of training dataset by adding randomly distorted images which are cropped, horizontally flipped, or adjusted in terms of hue, contrast and saturation. This way of distorting images will include different variation of images in training set, and will therefore make the CNN model we trained to generalize better in test dataset. We got this idea of data preprocessing from [Magnus Erik Hvass Pedersen](http://www.hvass-labs.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, the test dataset will be images cropped around center without any other adjustment. The cropped size is the same as that in training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Plot the distorted image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is ten examples of the 321st image in test dataset after preprocessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"../figs/distorted.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the distorted images are eithered flipped or adjusted in some way that varies from original image. These images will later be used to train CNN model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
