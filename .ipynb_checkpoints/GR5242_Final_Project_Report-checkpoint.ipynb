{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GR5242 Final Project Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team members:\n",
    "- Jia, Kewei (kj2408@columbia.edu)\n",
    "- Zhang, Yini (yz3005@columbia.edu)\n",
    "- Zhu, Chenyun (cz2434@columbia.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html) is an important image classification dataset. It consists of 60000 32x32 colour images in 10 classes (airplanes, automobiles, birds, cats, deer, dogs, frogs, horses, ships, and trucks), with 6000 images per class. There are 50000 training images and 10000 test images.<br>\n",
    "\n",
    "The **GOALS** of this project are to:\n",
    "- Learn how to preprocess the image data\n",
    "- Implement different Convolutional Neural Networks (CNN) classifiers using GPU-enabled Tensorflow and Keras API\n",
    "- Compare different CNN architectures\n",
    "\n",
    "**Tools:**\n",
    "- GPU-enabled Tensorflow\n",
    "- Keras API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Exploration & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Please refer to the *Data Exploration and Preprocessing.ipynb* for detailed code.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The version we used is [CIFAR-10 python version](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz).\n",
    "\n",
    "The original CIFAR 10 training dataset has five batches of files, each contains 10,000 images. The test dataset has one file that contains 10,000 images. We use functions in our script **load_data_helper_functions.py** to load both images and labels in training and test data.\n",
    "\n",
    "The training set we get is numpy ndarray with shape (50,000, 3072) and test set is numpy ndarray with shape (10,000, 3072). Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n",
    "\n",
    "The labels for training and test dataset are numpy array with shape (50,000, 1) and (10,000, 1). They are not one-hot-encoding yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we reshape each row into a (32,32,3) numpy array, with one inner array as one pixel with three channels: red, green and blue. The reshaped training data is of shape (50,000, 32, 32, 3). The reshaped test data is of shape (10,000, 32, 32, 3).\n",
    "\n",
    "Then we plot the first 10 images in training set with true class labels. This is for better understanding of the dataset. The images are plotted using functions in our script **preprocess_data.py**.\n",
    "\n",
    "__The first 10 images in training set:__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"figs/first10.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare data for training CNN models, we do the following things: \n",
    "\n",
    "First, we convert image labels to one-hot-encoding.\n",
    "\n",
    "Next, we inflate the size of training dataset by adding randomly distorted images which are cropped, horizontally flipped, or adjusted in terms of hue, contrast and saturation. This way of distorting images will include different variation of images in training set, and will therefore make the CNN model we trained to generalize better in test dataset. We got this idea of data preprocessing from [Magnus Erik Hvass Pedersen](http://www.hvass-labs.org/).\n",
    "\n",
    "Last, the test dataset will be images cropped around center without any other adjustment. The cropped size is the same as that in training set.\n",
    "\n",
    "__Plot the distorted image__<br>\n",
    "Here are 10 examples of the 321st image in test dataset after preprocessing:\n",
    "\n",
    "<img style=\"float: left;\" src=\"figs/distorted.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the distorted images are eithered flipped or adjusted in some way that varies from original image. These images will later be used to train CNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convolutional Neural Networks (CNN) with Keras\n",
    "### 2-1. Brief Introduction for Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano.(1)' The reasons we tried Keras are as follows:\n",
    "- Easy to get started with\n",
    "- Results in much more readable and succinct code\n",
    "- Able to run on GPU (much faster than CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. CNN with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__I. We first created the basic CNN with 100 Epochs.__<br>\n",
    "(Please refer to the *Keras_CNN_Baseline.ipynb* for detailed code.)\n",
    "\n",
    "__Architecture:__ <br>\n",
    "input = ($32\\times32\\times3$) -- <br>\n",
    "2D convolution layer with filters size $32$ and kernel size $3\\times3$ plus ReLU activation -- <br>\n",
    "2D convolution layer with filters size $32$ and kernel size $3\\times3$ plus ReLU activation -- <br>\n",
    "2D Maxpooling -- <br>\n",
    "20% Dropout -- <br>\n",
    "\n",
    "2D convolution layer with filters size $64$ and kernel size $3\\times3$ plus ReLU activation -- <br>\n",
    "2D convolution layer with filters size $64$ and kernel size $3\\times3$ plus ReLU activation -- <br>\n",
    "2D Maxpooling -- <br>\n",
    "25% Dropout -- <br>\n",
    "Softmax Output\n",
    "\n",
    "__Baseline CNN Result:__\n",
    "\n",
    "<img style=\"float: left; width:60%\" src=\"output/baseline_CNN.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Insights:__ <br>\n",
    "Notice that the test result is 79.7%. Let's try to add more layers to the model and see if the test accuracy has any improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__II. Now we added more layers to the previous model.__<br>\n",
    "(Please refer to the *Keras_CNN_Baseline_More_Layer.ipynb* for detailed code.)\n",
    "\n",
    "__Architecture:__ <br>\n",
    "input = ($32\\times32\\times3$) -- <br>\n",
    "2D convolution layer with filters size $32$ and kernel size $3\\times3$ plus ReLU activation -- <br>\n",
    "2D convolution layer with filters size $32$ and kernel size $3\\times3$ plus ReLU activation -- <br>\n",
    "2D Maxpooling -- <br>\n",
    "20% Dropout -- <br>\n",
    "\n",
    "2D convolution layer with filters size $64$ and kernel size $3\\times3$ plus ReLU activation -- <br>\n",
    "2D convolution layer with filters size $64$ and kernel size $3\\times3$ plus ReLU activation -- <br>\n",
    "2D Maxpooling -- <br>\n",
    "25% Dropout -- <br>\n",
    "\n",
    "2D convolution layer with filters size $128$ and kernel size $3\\times3$ plus ReLU activation -- <br>\n",
    "2D convolution layer with filters size $128$ and kernel size $3\\times3$ plus ReLU activation -- <br>\n",
    "2D Maxpooling -- <br>\n",
    "30% Dropout -- <br>\n",
    "Softmax Output\n",
    "\n",
    "__Baseline CNN with More Layers Result:__\n",
    "\n",
    "<img style=\"float: left; width:60%\" src=\"output/baseline_CNN_moreLayers.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Insights:__<br>\n",
    "The good thing is test accuracy increases from 79.7% to 83.1%. However, the model seems overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__III. Try to prevent overfitting by adding batchnormalization and kernel regularizer__<br>\n",
    "Idea from the Kaggle comment of [EricAlcaideAldeano](https://www.kaggle.com/ericalcaide9834/discussion) <br>\n",
    "(Please refer to the *Keras_CNN_Prevent_Overfitting.ipynb* for detailed code.)\n",
    "\n",
    "__Architecture:__ <br>\n",
    "input = ($32\\times32\\times3$) -- <br>\n",
    "2D convolution layer with filters size $32$ and kernel size $3\\times3$ plus ReLU activation and *regularizer(0.001)* -- <br>\n",
    "*BatchNormalization* -- <br>\n",
    "2D convolution layer with filters size $32$ and kernel size $3\\times3$ plus ReLU activation and *regularizer(0.001)* -- <br>\n",
    "*BatchNormalization* -- <br>\n",
    "2D Maxpooling -- <br>\n",
    "20% Dropout -- <br>\n",
    "\n",
    "2D convolution layer with filters size $64$ and kernel size $3\\times3$ plus ReLU activation and *regularizer(0.001)* -- <br>\n",
    "*BatchNormalization* -- <br>\n",
    "2D convolution layer with filters size $64$ and kernel size $3\\times3$ plus ReLU activation and *regularizer(0.001)* -- <br>\n",
    "*BatchNormalization* -- <br>\n",
    "2D Maxpooling -- <br>\n",
    "25% Dropout -- <br>\n",
    "\n",
    "2D convolution layer with filters size $128$ and kernel size $3\\times3$ plus ReLU activation and *regularizer(0.001)* -- <br>\n",
    "*BatchNormalization* -- <br>\n",
    "2D convolution layer with filters size $128$ and kernel size $3\\times3$ plus ReLU activation and *regularizer(0.001)* -- <br>\n",
    "*BatchNormalization* -- <br>\n",
    "2D Maxpooling -- <br>\n",
    "30% Dropout -- <br>\n",
    "Softmax Output\n",
    "\n",
    "__ Previous Model with Batchnorm and Kernel Regularizer Added Result:__\n",
    "\n",
    "<img style=\"float: left; width:60%\" src=\"output/prevent_overfit.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Insights:__<br>\n",
    "After applied batchnormalization and regularizer, we can see the test accuracy 85.2% is better than the previous model 83.1%. In addition, the generalization of the model improves as we can see in the graph (the gap between training accuracy and validation accuracy is smaller than before)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Findings of CNN with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add relatively more layers can achieve higher accuracy.\n",
    "- Batchnormalization and kernel regularizaer can help us prevent overfitting and keep the weights small so that the model can generalize well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply data augmentation to the model. It takes 17 hours to run 25 epochs so the limited time is the main challenge for us to add data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) *Keras: The Python Deep Learning Library. keras.io/#keras-the-python-deep-learning-library.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
